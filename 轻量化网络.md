# mobilenet

### mobilenet v1:

主要是两个策略：

1. 采用depthwise separable convolution，就是分离卷积核；
2. 设置宽度因子width multipler和分辨率因子resolution multiplier；



![在这里插入图片描述](https://img-blog.csdnimg.cn/20200407213327982.png)

![在这里插入图片描述](https://img-blog.csdnimg.cn/2020040721322344.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p1c3Rzb2xvdw==,size_16,color_FFFFFF,t_70)

![在这里插入图片描述](https://img-blog.csdnimg.cn/2020040721334067.png)

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200407213232120.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p1c3Rzb2xvdw==,size_16,color_FFFFFF,t_70)

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200407213350922.png)

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200407213247746.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p1c3Rzb2xvdw==,size_16,color_FFFFFF,t_70)

这样就把一个普通卷积拆分成了Depthwise+Pointwise两部分。其实Mobilenet v1就是做了如下转换：
普通卷积：3x3 Conv+BN+ReLU
Mobilenet卷积：3x3 Depthwise Conv+BN+ReLU 和 1x1 Pointwise Conv+BN+ReLU
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200407213431734.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p1c3Rzb2xvdw==,size_16,color_FFFFFF,t_70)
$$
 \frac{depthwise+pointwise}{conv} =  \frac{H*W*C*3*3+H*
 W*C*k}{H*W*C*3*3*k}= \frac{1}{k}+ \frac{1}{3*3}
$$
基本网络结构:

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200407213515119.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p1c3Rzb2xvdw==,size_16,color_FFFFFF,t_70)

**宽度乘法器：更薄的模型**
宽度乘法器α的作用就是对每一层均匀薄化。给定一个层以及宽度乘法器α，输入通道数M变成了αM并且输出通道数N变成αN。
加上宽度乘法器的深度可分离卷积的计算量如下：DK∗DK∗αM∗DF∗DF+αM∗αN∗DF∗DF

由于α∈(0,1]，一般设置为1\0.75\0.5\0.25。当α=1的时候就是最基本的MobileNet，当α<1时，就是薄化的MobileNet。宽度乘法器对计算量和参数量的减少大约α2倍。宽度乘法器可以应用在任何模型结构来定义一个更瘦的模型，并且权衡合理的精度、延迟的大小。宽度乘法器常用来薄化一个新的需要从头开始训练的网络结构。

##### 分辨率乘法器：约化表达
第二个薄化神经网络计算量的超参数是分辨率乘法器ρ。我们将其应用在输入图片以及每一层的内部表达中。实际上，我们通过设置ρ来隐式的设置输入的分辨率大小。
我们现在可以对网络中的核心层的深度可分离卷积加上宽度乘法器α以及分辨率乘法器ρ来表达计算量：DK∗DK∗αM∗ρDF∗ρDF+αM∗αN∗ρDF∗ρDF
其中ρ∈(0,1]，一般隐式的设置以便于输入网络的图像分辨率为224\192\160\128等。当ρ=1时为最基本的MobileNet，当ρ<1时，则为薄化的MobileNet。分辨率乘法器对网络约化大约ρ2倍。

(DK:kernel, DF:feature map, M:input channel, N:output channel)



### MobileNet v2

主要解决了V1在训练过程中非常容易特征退化的问题

**问题1：ReLU造成的低维度数据坍塌(collapses)**

channel少的feature map不应后接ReLU，否则会破坏feature map。

问题2：没有复用特征
在神经网络训练中如果某个卷积节点权重的值变为0就会“死掉”。因为对于任意输入，该节点的输出都是0。而ReLU对0值的梯度是0，所以后续无论怎么迭代这个节点的值都不会恢复了。而通过ResNet结构的特征复用，可以很大程度上缓解这种特征退化问题，如图18（这也从一个侧面说明ResNet为何好于VGG）。另外，一般情况训练网络使用的是float32浮点数；当使用低精度的float16时，这种特征复用可以更加有效的减缓退化。

基于上述两个问题，Mobilenet v2提出了Linear Bottlenecks+Inverted residual block作为网络基本结构，
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200407214159468.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p1c3Rzb2xvdw==,size_16,color_FFFFFF,t_70)

采用Inverted residual block结构。该结构使用Point wise convolution先对feature map进行升维，再在升维后的特征接ReLU，减少ReLU对特征的破坏。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200407214413574.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p1c3Rzb2xvdw==,size_16,color_FFFFFF,t_70)

主要区别有两点：

（1）Depth-wise convolution之前多了一个1*1的“扩张”层，目的是为了提升通道数，获得更多特征；

（2）最后不采用Relu，而是Linear，目的是防止Relu破坏特征。



### MobileNet V3

MobileNetV3是Google继MobileNet V1和MobileNet V2后的新作，主要使用了网络搜索算法(用NAS通过优化每个网络块来搜索全局网络结构，用NetAdapt算法搜索每个层的滤波器数量)，同时在MobileNet V2网络结构基础上进行改进，并引入了SE模块和提出了H-Swish激活函数。

1. **引入SE模块 **

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200407215926867.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p1c3Rzb2xvdw==,size_16,color_FFFFFF,t_70)

**2. 更改网络末端计算量大的层**

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200407224816169.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p1c3Rzb2xvdw==,size_16,color_FFFFFF,t_70)



**3. 更改初始卷积核的个数**
修改网络头部卷积核通道数的数量，Mobilenet v2中使用的是，作者发现，其实32可以再降低一点，所以这里改成了16，在保证了精度的前提下，降低了3ms的速度。

**4. H-Swish 激活函数**

它是最近的Swish非线性函数的改进版本，计算速度比Swish更快(但比ReLU慢)，更易于量化，精度上没有差异.

**5. NAS搜索全局结构和NetAdapt搜索层结构**



# shufflenet

## ShuffleNet V1

核心思想有两点：主要思路是使用Group convolution和Channel shuffle改进ResNet，可以看作是ResNet的压缩版本

1. 借鉴resnext分组卷积思想，但不同的是采用1x1卷积核；
2. 进行通道清洗，加强通道间的信息流通，提高信息表示能力。

#### 1. 逐点群卷积pointwise group convolution

这个就是采用resnext的思想，将通道分组，每组分别进行卷积操作，然后再把结果进行concat。但是不同于resnext的是，shufflenet采用的是1x1卷积核。

### 2. 通道清洗channel shuffle

什么是通道shuffle，就是在分组卷积后得到的feature map不直接进行concat，先将每组feature map按通道打乱，重新concat，如下图所示：

![这里写图片描述](https://img-blog.csdn.net/20180821195515832?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpdXhpYW8yMTQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

![这里写图片描述](https://img-blog.csdn.net/20180821200212714?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpdXhpYW8yMTQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

这里解释下为何要做Channel Shuffle操作：

ShuffleNet的本质是将卷积运算限制在每个Group内，这样模型的计算量取得了显著的下降。然而导致模型的信息流限制在各个Group内，组与组之间没有信息交换，如图15，这会影响模型的表示能力。因此，需要引入组间信息交换的机制，即Channel Shuffle操作。同时Channel Shuffle是可导的，可以实现end-to-end一次性训练网络。



### 网络结构：

这是resnet的两种经典的结构：注意Channel维度变化：256 D → 64 D → 256 D ，宛如一个中间细两端粗的瓶颈，所以称为“bottleneck”。



![在这里插入图片描述](https://img-blog.csdnimg.cn/20200407214547278.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p1c3Rzb2xvdw==,size_16,color_FFFFFF,t_70)

下图展示了ShuffleNet的结构，其中(a)就是加入Depthwise的ResNet bottleneck结构，而(b)和©是加入Group convolution和Channel Shuffle的ShuffleNet的结构。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200407214656943.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p1c3Rzb2xvdw==,size_16,color_FFFFFF,t_70)

评估逐点组卷积：分组的效果均比没有分组的效果好，但是某些模型随着组数增加，性能有下降，这就是通道间失去联系带来的问题

![这里写图片描述](https://img-blog.csdn.net/20180821201655920?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpdXhpYW8yMTQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

评估channel shuffle：shuffle会比没有shuffle效果好，而且对于组数越大，效果越好，说明了shuffle的重要性，也说明了上图中组数增加性能下降的问题。

![这里写图片描述](https://img-blog.csdn.net/20180821201705598?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpdXhpYW8yMTQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

与mobilenet的比较

![这里写图片描述](https://img-blog.csdn.net/20180821201824976?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpdXhpYW8yMTQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

### ShuffleNet V2

**1、探索卷积层的输入输出特征通道数对MAC指标的影响。**
实验结论是卷积层的输入和输出特征数相等时MAC最小，此时模型的速度最快

**2、探索卷积的group操作对MAC的影响。**
实验结论是过多的group操作会增大MAC，从而使模型变慢。

**3、探索模型设计的分支数量对模型速度的影响。**
实验结论是模型中的分支数量越少，模型速度越快。

**4、探索element-wise操作对模型速度的影响。**
实验结论是element-wise操作所带来的时间消耗远比在FLOPS上体现的数值要多，因此要尽可能减少element-wise操作。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200407215545363.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p1c3Rzb2xvdw==,size_16,color_FFFFFF,t_70)

上图(a) ShuffleNet v1 ，(b)ShuffleNet v1 降采样， ©ShuffleNet v2，(d)ShuffleNet v2 降采样

